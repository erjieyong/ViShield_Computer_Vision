{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "To deploy trained YOLO model using docker and upload to google cloud. Visualise using streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask : For listening and responding to streamlit calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py \n",
    "from flask import Flask, request, Response, stream_with_context\n",
    "import os \n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import argparse\n",
    "from base64 import b64encode\n",
    "\n",
    "# to allow us to import and call predict.py from within yolov7\n",
    "sys.path.insert(0, './yolov7/seg/segment/')\n",
    "import predict\n",
    "\n",
    "#to allow us to push images to roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"ENZ4UFQ5TkrSOtWuLtkb\")\n",
    "project = rf.workspace().project(\"snakes-oozrc\")\n",
    "\n",
    "api = Flask('ModelEndpoint')\n",
    "#########################\n",
    "##      FLASK API      ##\n",
    "#########################\n",
    "@api.route('/') \n",
    "def home(): \n",
    "    return {\"message\": \"Hello!\", \"success\": True}, 200\n",
    "\n",
    "@api.route('/predict', methods = ['POST']) \n",
    "def make_predictions():\n",
    "    url = request.get_json(force=True)\n",
    "    url = url[1:-1] #get rid of \" at the start and end of url\n",
    "    file_typ = url.split(\".\")[-1] #get the file type\n",
    "    file_link = 'target_image.'+file_typ \n",
    "    \n",
    "    img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tiff', 'dng', 'webp', 'mpo'] #acceptable image formats\n",
    "    vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'm4v', 'wmv', 'mkv', 'gif'] #acceptable video formats\n",
    "\n",
    "    # with the url, download and create the file locally\n",
    "    r = requests.get(url)\n",
    "    with open(file_link, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "    # originally predict.py is supposed to be called in command line. But as we are calling it within another .py script, \n",
    "    # we need to create other own parser to pass it to predict.py\n",
    "    # PREDICTION START---------------------------------------------------------------------------------------------\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights', nargs='+', type=str, help='model path(s)')\n",
    "    parser.add_argument('--source', type=str, help='file/dir/URL/glob, 0 for webcam')\n",
    "    parser.add_argument('--view-img', action='store_true', help='show results')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
    "    parser.add_argument('--project', default='./', help='save results to project/name')\n",
    "    \n",
    "    #check if file type is img or vid. If it is vid type, we will not save confidence level or text because we are not uploading them back to roboflow\n",
    "    if file_typ in img_formats:\n",
    "        opt = parser.parse_args(f\"--save-txt --save-conf --weights ./Models/151122_0115/weights/best.pt --source target_image.{file_typ}\".split())\n",
    "    elif file_typ in vid_formats:\n",
    "        opt = parser.parse_args(f\"--weights ./Models/151122_0115/weights/best.pt --source target_image.{file_typ}\".split())\n",
    "\n",
    "\n",
    "    import logging\n",
    "    logger = logging.getLogger('yolov5')\n",
    "    handler = logging.FileHandler('predict.log')\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    predict.main(opt)\n",
    "\n",
    "    # close the file handler\n",
    "    logger.removeHandler(handler)\n",
    "    handler.close()\n",
    " \n",
    "    # PREDICTION END----------------------------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "    #Active learning\n",
    "    #Read Results Files and Conditionally Upload\n",
    "\n",
    "    #If my model has a confidence of less than 70% for a prediction, let's help it\n",
    "    #out by uploading this image back to our dataset. Then we can add a ground truth\n",
    "    #label to it so that it will be included in our next training run and future \n",
    "    #prediction results will improve.\n",
    "    #Only do this for image files\n",
    "    image_upload_txt = None\n",
    "    if file_typ in img_formats:\n",
    "        MIN_CONF_THRESHOLD = 0.7 \n",
    "        predicted_image_dir = \"./exp/labels\"\n",
    "        image_dir = \"./\"\n",
    "\n",
    "        for i,txt_file in enumerate(os.listdir(predicted_image_dir)):\n",
    "            print(i, txt_file)\n",
    "            with open(os.path.join(predicted_image_dir,txt_file), 'r') as fid:\n",
    "                for line in fid:\n",
    "                    label, x1, y1, x2, y2, conf = line.split(\" \")\n",
    "                    conf = float(conf)\n",
    "                    if conf < MIN_CONF_THRESHOLD:\n",
    "                        image_name = txt_file[:-4]\n",
    "                        image_upload_txt = f\"Image has a low confidence prediction below 0.7, uploading to project SNAKES in roboflow for active learning\"\n",
    "                        print(image_upload_txt)\n",
    "                        #Upload via Roboflow pip package\n",
    "                        project.upload(os.path.join(image_dir,f'{file_link}'))\n",
    "                    break\n",
    "            \n",
    "    # check for file type and send back the file to streamlit with the appropriate mimetype\n",
    "    # take note that html5 player which streamlit uses only supports H264 encoding and not standard mp4v.\n",
    "    # Hence we need to use mkv format which allows for H264 encoding. Changes were made directly to predict.py to allow for this encoding method\n",
    "    # We also do encoding to b64 and utf8 instead of just `return send_file(filename, mimetype='video/mkv')` which is faster.\n",
    "    # this is because we wanted to send more information together with the image/video\n",
    "    # normally, we can send more information on top of send_file by using headers or cookies. But streamlit does not allow.\n",
    "    # Hence we have to use this encoding and decoding method which takes slightly longer.\n",
    "    if file_typ in img_formats:\n",
    "        filename = \"./exp/\"+file_link\n",
    "        # text that you want to send back together with file\n",
    "        output = {\n",
    "            \"type\" : \"img\",\n",
    "            \"prompt\": image_upload_txt\n",
    "        }\n",
    "        #send logs\n",
    "        with open(\"./predict.log\", \"r\", encoding='utf-8') as log:\n",
    "            content = log.read()\n",
    "            output['logs'] = content\n",
    "        #delete the predict.py log file\n",
    "        if os.path.exists(\"predict.log\"):\n",
    "            os.remove(\"predict.log\")\n",
    "        #send image\n",
    "        with open(filename, 'rb') as img:\n",
    "            content = img.read()\n",
    "            #we first encode to b64, which returns in byte\n",
    "            #then we change it again to utf8 string type so that it can be jsonify\n",
    "            output['img'] = b64encode(content).decode('utf8')\n",
    "        \n",
    "        return output\n",
    "    elif file_typ in vid_formats:\n",
    "        filename = \"./exp/target_image.webm\"\n",
    "        output = {\n",
    "            \"type\" : \"vid\",\n",
    "            \"prompt\": \"Active learning for videos is still in progress\"\n",
    "        }\n",
    "        #send logs\n",
    "        with open(\"./predict.log\", \"r\", encoding='utf-8') as log:\n",
    "            content = log.read()\n",
    "            output['logs'] = content\n",
    "        #delete the predict.py log file\n",
    "        if os.path.exists(\"predict.log\"):\n",
    "            os.remove(\"predict.log\")\n",
    "        #send video\n",
    "        with open(filename, 'rb') as f:\n",
    "            content = f.read()\n",
    "            #we first encode to b64, which returns in byte\n",
    "            #then we change it again to utf8 string type so that it can be jsonify\n",
    "            output['vid'] = b64encode(content).decode('utf8')\n",
    "        \n",
    "        return output\n",
    "        \n",
    "if __name__ == '__main__': \n",
    "    api.run(host='0.0.0.0', \n",
    "            debug=True, \n",
    "            port=int(os.environ.get(\"PORT\", 8080))\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit: User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "from base64 import b64decode\n",
    "\n",
    "st.image('https://generalassemblydsi32.s3.ap-southeast-1.amazonaws.com/Logo.png', width = 100)\n",
    "st.title(\"ViShield\")\n",
    "st.write(\"Vision Shield, An app that helps you to filter out snakes from your images and videos\")\n",
    "st.caption(\"For more information, visit my [github](https://github.com/erjieyong?tab=repositories) or contact me directly at [erjieyong@gmail.com](mailto:erjieyong@gmail.com)\")\n",
    "\n",
    "with st.form(key='my_form'):\n",
    "    url = st.text_input(\"Image / Video URL\", placeholder=\"Please enter image url\")\n",
    "    st.caption(\"Please ensure that your url ends with image or video formats such as .jpg, .png, .gif, .mp4\")\n",
    "    submit = st.form_submit_button(label='Submit')\n",
    "\n",
    "if submit:\n",
    "    img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tiff', 'dng', 'webp', 'mpo'] #acceptable image formats\n",
    "    vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'm4v', 'wmv', 'mkv', 'gif', 'webm'] #acceptable video formats\n",
    "    file_typ = url.split(\".\")[-1] #get the file type\n",
    "\n",
    "    if len(url) == 0 or (file_typ not in img_formats and file_typ not in vid_formats):\n",
    "        st.write(\"Please enter a valid url ending with the correct image or video formats\")\n",
    "    else:\n",
    "        with st.spinner('🪄 ✨Gathering magic dusts...✨'):\n",
    "            api_url = 'https://jy-dsi-capstone-no755hevjq-as.a.run.app'\n",
    "            api_route = '/predict'\n",
    "            \n",
    "            response = requests.post(f'{api_url}{api_route}', json=json.dumps(url)) # json.dumps() converts dict to JSON\n",
    "            response = response.json()\n",
    "\n",
    "            logs = None\n",
    "            print(response['logs'])\n",
    "            \n",
    "            print(type(response['logs']))\n",
    "            print(len(response['logs']))\n",
    "\n",
    "            if response['type'] == \"img\":\n",
    "                img = response['img'].encode('utf8')\n",
    "                img = b64decode(img)\n",
    "                st.image(img)\n",
    "                st.subheader(\"Prediction Logs\")\n",
    "                st.text(response['logs'])\n",
    "                st.write(response['prompt'])\n",
    "            elif response['type'] == \"vid\":\n",
    "                vid = response['vid'].encode('utf8')\n",
    "                vid = b64decode(vid)\n",
    "                st.video(vid)\n",
    "                st.subheader(\"Prediction Logs\")\n",
    "                st.text(response['logs'])\n",
    "                st.text(\"Video is encoded in VP90 .WEBM format as opposed to H264 due to licensing issue\")\n",
    "                st.text(response['prompt'])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker : to zip files and tell GCP how to build container (environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.8 \n",
    "\n",
    "# Copy all the files needed for the app to work\n",
    "COPY inference.py .\n",
    "COPY Models/151122_0115/weights/best.pt ./Models/151122_0115/weights/best.pt\n",
    "COPY requirements.txt .\n",
    "COPY yolov7/ ./yolov7/\n",
    "\n",
    "# Install all the necessary libraries\n",
    "RUN apt-get update && apt-get install -y git ffmpeg libsm6 libxext6 libgl1-mesa-glx libgl1 libglib2.0-0 python3-opencv\n",
    "RUN pip install -r requirements.txt\n",
    "RUN pip install git+https://github.com/facebookresearch/detectron2.git\n",
    "RUN pip install opencv-python\n",
    "RUN pip install opencv-contrib-python-headless\n",
    "\n",
    "# Run the API!\n",
    "CMD python inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "flask\n",
    "torch==1.10.1\n",
    "torchvision==0.11.2\n",
    "torchaudio==0.10.1\n",
    "roboflow\n",
    "lxml==4.9.1\n",
    "av\n",
    "\n",
    "# YOLOv5 requirements\n",
    "# Usage: pip install -r requirements.txt\n",
    "\n",
    "# Base ----------------------------------------\n",
    "matplotlib>=3.2.2\n",
    "numpy>=1.18.5\n",
    "opencv-python>=4.1.1\n",
    "Pillow>=7.1.2\n",
    "PyYAML>=5.3.1\n",
    "requests>=2.23.0\n",
    "scipy>=1.4.1\n",
    "tqdm>=4.64.0\n",
    "protobuf<=3.20.1  # https://github.com/ultralytics/yolov5/issues/8012\n",
    "\n",
    "# Logging -------------------------------------\n",
    "tensorboard>=2.4.1\n",
    "# wandb\n",
    "# clearml\n",
    "\n",
    "# Plotting ------------------------------------\n",
    "seaborn>=0.11.0\n",
    "\n",
    "# Export --------------------------------------\n",
    "# coremltools>=5.2  # CoreML export\n",
    "# onnx>=1.9.0  # ONNX export\n",
    "# onnx-simplifier>=0.4.1  # ONNX simplifier\n",
    "# nvidia-pyindex  # TensorRT export\n",
    "# nvidia-tensorrt  # TensorRT export\n",
    "# scikit-learn==0.19.2  # CoreML quantization\n",
    "# tensorflow>=2.4.1  # TFLite export (or tensorflow-cpu, tensorflow-aarch64)\n",
    "# tensorflowjs>=3.9.0  # TF.js export\n",
    "# openvino-dev  # OpenVINO export\n",
    "\n",
    "# Extras --------------------------------------\n",
    "ipython  # interactive notebook\n",
    "psutil  # system utilization\n",
    "thop>=0.1.1  # FLOPs computation\n",
    "# albumentations>=1.0.3\n",
    "# pycocotools>=2.0  # COCO mAP\n",
    "# roboflow\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c91e0d3abcf45be7fbdd62126f8c5b0be06d3397fd7a6bd67ca08a695de2f61c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
